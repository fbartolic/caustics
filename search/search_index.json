{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00a4 caustics is a code for computing microlensing light curves of single, binary, and triple lens systems using the contour integration method. It is built using the JAX library which enables the computation of exact gradients of the code outputs with respect to all input parameters through the use of automatic differentiation . It has the following feautures: Fast (miliseconds) and accurate computation of binary and triple lens microlensing light curves for extended limb-darkened sources. Automatic differentiation enables the use of gradient-based inference methods such as Hamiltonian Monte Carlo when fitting multiple lens microlensing light curves. A differentiable JAX version of a complex polynomial root solver CompEA which uses the Aberth-Ehrlich method to obtain all roots of a complex polynomial at once using an implicit deflation strategy. The gradient of the solutions with respect to the polynomial coefficients is obtained through implicit differentiation . Hexadecapole approximation from Cassan 2017 is used to substantially speed up the computation of the magnification everywhere except near the caustics. Installation \u00a4 caustics is still being actively developed and is not yet released on PyPI. To install the development version, clone this repository, create a new conda environment, cd into the repository and run conda env update -- file environment . yml && pip install . caustics does not currently support Apple M1 processors except via Rosetta emulation. To install it open the terminal through Rosetta and the command from above. References \u00a4 caustics paper coming soon! Light-curve calculations for triple microlensing systems On a compensated Ehrlich-Aberth method for the accurate computation of all polynomial roots A robust and efficient method for calculating the magnification of extended sources caused by gravitational lenses VBBINARYLENSING: a public package for microlensing light-curve computation Fast computation of quadrupole and hexadecapole approximations in microlensing with a single point-source evaluation","title":"Home"},{"location":"#overview","text":"caustics is a code for computing microlensing light curves of single, binary, and triple lens systems using the contour integration method. It is built using the JAX library which enables the computation of exact gradients of the code outputs with respect to all input parameters through the use of automatic differentiation . It has the following feautures: Fast (miliseconds) and accurate computation of binary and triple lens microlensing light curves for extended limb-darkened sources. Automatic differentiation enables the use of gradient-based inference methods such as Hamiltonian Monte Carlo when fitting multiple lens microlensing light curves. A differentiable JAX version of a complex polynomial root solver CompEA which uses the Aberth-Ehrlich method to obtain all roots of a complex polynomial at once using an implicit deflation strategy. The gradient of the solutions with respect to the polynomial coefficients is obtained through implicit differentiation . Hexadecapole approximation from Cassan 2017 is used to substantially speed up the computation of the magnification everywhere except near the caustics.","title":"Overview"},{"location":"#installation","text":"caustics is still being actively developed and is not yet released on PyPI. To install the development version, clone this repository, create a new conda environment, cd into the repository and run conda env update -- file environment . yml && pip install . caustics does not currently support Apple M1 processors except via Rosetta emulation. To install it open the terminal through Rosetta and the command from above.","title":"Installation"},{"location":"#references","text":"caustics paper coming soon! Light-curve calculations for triple microlensing systems On a compensated Ehrlich-Aberth method for the accurate computation of all polynomial roots A robust and efficient method for calculating the magnification of extended sources caused by gravitational lenses VBBINARYLENSING: a public package for microlensing light-curve computation Fast computation of quadrupole and hexadecapole approximations in microlensing with a single point-source evaluation","title":"References"},{"location":"api/extended_source/","text":"Extended source \u00a4 caustics.extended_source \u00a4 Compute the magnification of an extended source using contour integration. mag_extended_source ( w0 , rho , nlenses = 2 , npts_limb = 150 , limb_darkening = False , u1 = 0.0 , npts_ld = 100 , roots_itmax = 2500 , roots_compensated = False , ** params ) \u00a4 Compute the magnification of an extended source with radius rho for a system with nlenses lenses. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i*\\psi}\\) . The magnification is computed using contour integration in the image plane. Boolean flag limb_darkening indicated whether linear limb-darkening needs to taken into account. If limb_darkening is set to True the linear limb-darkening coefficient u1 needs to be specified as well. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Note Turning on limb-darkening ( limb_darkening=True ) slows down the computation by up to an order of magnitude. Parameters: Name Type Description Default w0 complex Source position in the complex plane. required rho float Source radius in Einstein radii. required nlenses int Number of lenses in the system. 2 npts_limb int Initial number of points uniformly distributed on the source limb when computing the point source magnification. The final number of points is greater than this value because the number of points is decreased geometrically by a factor of 1/2 until it reaches 2. 150 limb_darkening bool If True, compute the magnification of a limb-darkened source. If limb_darkening is enabled the u1 linear limb-darkening coefficient needs to be specified. Defaults to False. False u1 float Linear limb darkening coefficient. Defaults to 0.. 0.0 npts_ld int Number of points at which the stellar brightness function is evaluated when computing contour integrals \\(\\int P(z_1^\\prime, z_2) dz_1^\\prime\\) and \\(\\int Q(z_1, z_2^\\prime) dz_2^\\prime\\) (see Dominik 1998). Defaults to 100. 100 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description float Total magnification at the source position w0 .","title":"Extended source"},{"location":"api/extended_source/#extended-source","text":"","title":"Extended source"},{"location":"api/extended_source/#caustics.extended_source","text":"Compute the magnification of an extended source using contour integration.","title":"extended_source"},{"location":"api/extended_source/#caustics.extended_source.mag_extended_source","text":"Compute the magnification of an extended source with radius rho for a system with nlenses lenses. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i*\\psi}\\) . The magnification is computed using contour integration in the image plane. Boolean flag limb_darkening indicated whether linear limb-darkening needs to taken into account. If limb_darkening is set to True the linear limb-darkening coefficient u1 needs to be specified as well. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Note Turning on limb-darkening ( limb_darkening=True ) slows down the computation by up to an order of magnitude. Parameters: Name Type Description Default w0 complex Source position in the complex plane. required rho float Source radius in Einstein radii. required nlenses int Number of lenses in the system. 2 npts_limb int Initial number of points uniformly distributed on the source limb when computing the point source magnification. The final number of points is greater than this value because the number of points is decreased geometrically by a factor of 1/2 until it reaches 2. 150 limb_darkening bool If True, compute the magnification of a limb-darkened source. If limb_darkening is enabled the u1 linear limb-darkening coefficient needs to be specified. Defaults to False. False u1 float Linear limb darkening coefficient. Defaults to 0.. 0.0 npts_ld int Number of points at which the stellar brightness function is evaluated when computing contour integrals \\(\\int P(z_1^\\prime, z_2) dz_1^\\prime\\) and \\(\\int Q(z_1, z_2^\\prime) dz_2^\\prime\\) (see Dominik 1998). Defaults to 100. 100 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description float Total magnification at the source position w0 .","title":"mag_extended_source()"},{"location":"api/lightcurve/","text":"Lightcurve \u00a4 caustics.lightcurve \u00a4 Computing the magnification of an extended source at an arbitrary set of points in the source plane. mag ( w_points , rho , nlenses = 2 , npts_limb = 200 , limb_darkening = False , u1 = 0.0 , npts_ld = 100 , roots_itmax = 2500 , roots_compensated = False , ** params ) \u00a4 Compute the extended source magnification for a system with nlenses lenses and a source star radius rho at a set of complex points w_points in the source plane. This function calls either [ caustics.multipole._mag_hexadecapole ] or caustics.mag_extended_source at each point in w_points depending on whether or not the hexadecapole approximation is accurate enough at that point. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i\\psi}\\) . The magnification is computed using contour integration in the image plane. Boolean flag limb_darkening indicates whether linear limb-darkening needs to taken into account. If limb_darkening is set to True the linear limb-darkening coefficient u1 needs to be specified as well. Note that turning on this flag slows down the computation by up to an order of magnitude. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Note Turning on limb-darkening ( limb_darkening=True ) slows down the computation by up to an order of magnitude. Warning At the moment the test determining whether or not to use the hexadecapole approximation does not work for triple lenses so the function will use full contour integration at every point. This substantially slows down the computation. See https://github.com/fbartolic/caustics/issues/19. Parameters: Name Type Description Default w_points array_like Source positions in the complex plane. required rho float Source radius in Einstein radii. required nlenses int Number of lenses in the system. 2 npts_limb int Initial number of points uniformly distributed on the source limb when computing the point source magnification. The final number of points is greater than this value because the number of points is decreased geometrically by a factor of 1/2 until it reaches 2. 200 limb_darkening bool If True, compute the magnification of a limb-darkened source. If limb_darkening is enabled the u1 linear limb-darkening coefficient needs to be specified. Defaults to False. False u1 float Linear limb darkening coefficient. Defaults to 0.. 0.0 npts_ld int Number of points at which the stellar brightness function is evaluated when computing contour integrals \\(\\int P(z_1^\\prime, z_2) dz_1^\\prime\\) and \\(\\int Q(z_1, z_2^\\prime) dz_2^\\prime\\) (see Dominik 1998). Defaults to 100. s (float): Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. 100 q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description array_like Magnification array.","title":"Lightcurve"},{"location":"api/lightcurve/#lightcurve","text":"","title":"Lightcurve"},{"location":"api/lightcurve/#caustics.lightcurve","text":"Computing the magnification of an extended source at an arbitrary set of points in the source plane.","title":"lightcurve"},{"location":"api/lightcurve/#caustics.lightcurve.mag","text":"Compute the extended source magnification for a system with nlenses lenses and a source star radius rho at a set of complex points w_points in the source plane. This function calls either [ caustics.multipole._mag_hexadecapole ] or caustics.mag_extended_source at each point in w_points depending on whether or not the hexadecapole approximation is accurate enough at that point. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i\\psi}\\) . The magnification is computed using contour integration in the image plane. Boolean flag limb_darkening indicates whether linear limb-darkening needs to taken into account. If limb_darkening is set to True the linear limb-darkening coefficient u1 needs to be specified as well. Note that turning on this flag slows down the computation by up to an order of magnitude. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Note Turning on limb-darkening ( limb_darkening=True ) slows down the computation by up to an order of magnitude. Warning At the moment the test determining whether or not to use the hexadecapole approximation does not work for triple lenses so the function will use full contour integration at every point. This substantially slows down the computation. See https://github.com/fbartolic/caustics/issues/19. Parameters: Name Type Description Default w_points array_like Source positions in the complex plane. required rho float Source radius in Einstein radii. required nlenses int Number of lenses in the system. 2 npts_limb int Initial number of points uniformly distributed on the source limb when computing the point source magnification. The final number of points is greater than this value because the number of points is decreased geometrically by a factor of 1/2 until it reaches 2. 200 limb_darkening bool If True, compute the magnification of a limb-darkened source. If limb_darkening is enabled the u1 linear limb-darkening coefficient needs to be specified. Defaults to False. False u1 float Linear limb darkening coefficient. Defaults to 0.. 0.0 npts_ld int Number of points at which the stellar brightness function is evaluated when computing contour integrals \\(\\int P(z_1^\\prime, z_2) dz_1^\\prime\\) and \\(\\int Q(z_1, z_2^\\prime) dz_2^\\prime\\) (see Dominik 1998). Defaults to 100. s (float): Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. 100 q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description array_like Magnification array.","title":"mag()"},{"location":"api/linalg/","text":"Linear algebra \u00a4 This module contains a function marginalized_log_likelihood which computes the log likelihood of a microlensing model marginalized over the linear flux parameters \\(\\beta\\equiv(F_s,F_b)^\\intercal\\) . This function is intended to be used a as replacement for the standard likelihood function when optimizing the likelihood or doing MCMC. The marginalization is standard practice when fitting microlensing events because it reduces the number of parameters in the model by the number of linear parameters in the model. For light curves consisting of multiple independent observations (for example, those observed by different observatories) this is a necessary step because there could be dozens of linear parameters in the model. The way this is traditionally done in microlensing is by solving for the linear parameters conditional on fixed values of the nonlinear parameters using linear least squares. This procedure is justified in some circumstances but it is not valid if the data covariance matrix is dense (for example, if we are using a Gaussian Process to model correlated noise in the light curves or stellar variability of the source star). Below, I show how to analytically marginalize over the linear parameters in the general case. The observed flux \\(\\mathbf f\\) can be written as a linear model \\begin{equation} \\mathbf f = \\mathbf M\\,\\boldsymbol\\beta \\end{equation} where \\(\\mathbf M\\) is the design matrix which depends on some nonlinear parameters \\(\\boldsymbol\\theta\\) : \\[\\begin{equation} \\mathbf{M}\\equiv \\begin{pmatrix} \\tilde{A}(t_1;\\boldsymbol\\theta) & 1 \\\\ \\tilde{A}(t_2;\\boldsymbol\\theta) & 1 \\\\ \\vdots & \\vdots \\\\ \\tilde{A}(t_{N};\\boldsymbol\\theta) & 1 \\end{pmatrix} \\end{equation}\\] Assuming that we place a Gaussian prior on the linear parameters \\(\\boldsymbol\\beta\\) with mean \\(\\boldsymbol\\mu\\) and covariance \\(\\boldsymbol\\Lambda\\) , one can show that the marginal likelihood \\(\\ln\\int p(\\mathbf f|\\boldsymbol\\theta)\\,p(\\boldsymbol\\beta|\\boldsymbol\\theta)d\\boldsymbol\\beta\\) is given by \\[\\begin{equation} \\mathrm{LL}(\\boldsymbol\\theta)=-\\frac{1}{2}\\left( \\mathbf{f}-\\mathbf{M}\\boldsymbol{\\mu}\\right)^\\intercal\\left(\\mathbf{C} + \\mathbf{M}\\boldsymbol{\\Lambda}\\mathbf{M}^\\intercal\\right)^{-1} \\left( \\mathbf{f}-\\mathbf{M}\\boldsymbol{\\mu}\\right) - \\frac{1}{2}\\ln\\left| \\mathbf{C} + \\mathbf{M}\\boldsymbol{\\Lambda}\\mathbf{M}^\\intercal\\right| \\end{equation}\\] To compute the inverse and the determinant of the covariance matrix of marginalized likelihood we can use the matrix inversion lemma (see Appendix A3 of R&W ): \\[\\begin{align} & \\left(\\mathbf{C}+\\mathbf{M} \\boldsymbol{\\Lambda} \\mathbf{M}^{\\intercal}\\right)^{-1}=\\mathbf{C}^{-1}-\\mathbf{C}^{-1} \\mathbf{M}\\left(\\boldsymbol{\\Lambda}^{-1}+\\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\mathbf{M}\\right)^{-1} \\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\\\ & \\ln\\left|\\mathbf{C}+\\mathbf{M} \\mathbf{\\Lambda} \\mathbf{M}^{\\intercal}\\right|=\\ln|\\mathbf{C}| +\\ln|\\boldsymbol{\\Lambda}| + \\ln\\left|\\boldsymbol{\\Lambda}^{-1}+\\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\mathbf{M}\\right| \\end{align}\\] However, if we marginalize over the linear parameters, how can we obtain their values in order to, for example, produce a plot of the model fit? The answer, from the paper linked above, is that the distribution over \\(\\boldsymbol\\beta\\) conditional on particular values of the nonlinear parameters \\(\\boldsymbol\\theta\\) is a Gaussian \\(\\mathcal{N}(\\boldsymbol\\beta;\\mathbf a,\\mathbf A)\\) where \\[\\begin{align} &\\mathbf{A}^{-1}=\\boldsymbol\\Lambda^{-1}+\\mathbf{M}^{\\intercal}\\mathbf{C}^{-1}\\mathbf{M} \\\\ &\\mathbf a = \\mathbf A\\left(\\boldsymbol\\Lambda^{-1}\\boldsymbol\\mu+\\mathbf{M}^{\\intercal}\\mathbf{C}^{-1}\\mathbf{f}\\right) \\end{align}\\] If we had posterior samples of the nonlinear parameters \\(\\boldsymbol\\theta\\) we could could use this distribution to generate samples of the linear parameters. In marginalized_log_likelihood I use the standard least squares solution for \\(\\boldsymbol\\beta\\) if the data covariance matrix is diagonal because it's faster than the matrix operations in \\(\\mathrm{LL}(boldsymbol\\theta)\\) . Otherwise I use the full analytic marginalization. caustics.linalg \u00a4 marginalized_log_likelihood ( A_list , fobs_list , C_inv_list , dense_covariance = False , Lam_sd = 10000.0 ) \u00a4 Compute the log-likelihood for a microlensing light curve marginalized over over the linear flux parameters \\(\\boldsymbol\\beta\\equiv(F_s, F_b)^\\intercal\\) . The function takes a list of magnification vectors, a list of observed fluxes and a list of inverse data covariance matrices as an input, one element of the list represents and independent set of observations, for instance light curves from different observatories. The total log-likelihood is then a sum of the log-likelihoods for each light curve. If dense_covariance is False, the inverse data covariance matrices are assumed to be 1D vectors containing the elements on the diagonal. In that case, the most efficient way to marginalize over the linear parameters in the likelihood is to solve the linear least squares problem conditional on fixed values of the nonlinear parameters (which determine the magnification). If dense_covariance is True, the inverse covariance matrices are assumed to be dense matrices. In that case we have to compute the full marginal likelihood. This increases the computational cost of the likelihood evaluation. Parameters: Name Type Description Default A_list list [ array_like ] List of 1D magnification arrays, one per independent observation. required fobs_list list [ array_like ] List of 1D observed flux arrays. required C_inv_list list [ array_like ] List of nverse data covariance matrices. If dense_covariance is False, this is a 1D vector containing the diagonal elements of the covariance matrix. If dense_covariance is True, this is a dense matrix. required dense_covariance bool Flag indicating whether C_inv is dense or diagonal. Defaults to False. False Lam_sd float Standard deviation of the Gaussian prior on the linear flux parameters. The prior is assumed to be a zero mean independent Gaussian with standard deviation Lam_sd for both linear parameters. Defaults to 1e04. 10000.0 Returns: Name Type Description tuple If dense_covariance is False, returns a tuple \\((\\boldsymbol\\beta, \\mathrm{LL}(\\boldsymbol\\theta))\\) containing the least-squares solution for the linear parameters and the log-likelihood. Otherwise, the first element of the tuple is 0.","title":"Linear algebra"},{"location":"api/linalg/#linear-algebra","text":"This module contains a function marginalized_log_likelihood which computes the log likelihood of a microlensing model marginalized over the linear flux parameters \\(\\beta\\equiv(F_s,F_b)^\\intercal\\) . This function is intended to be used a as replacement for the standard likelihood function when optimizing the likelihood or doing MCMC. The marginalization is standard practice when fitting microlensing events because it reduces the number of parameters in the model by the number of linear parameters in the model. For light curves consisting of multiple independent observations (for example, those observed by different observatories) this is a necessary step because there could be dozens of linear parameters in the model. The way this is traditionally done in microlensing is by solving for the linear parameters conditional on fixed values of the nonlinear parameters using linear least squares. This procedure is justified in some circumstances but it is not valid if the data covariance matrix is dense (for example, if we are using a Gaussian Process to model correlated noise in the light curves or stellar variability of the source star). Below, I show how to analytically marginalize over the linear parameters in the general case. The observed flux \\(\\mathbf f\\) can be written as a linear model \\begin{equation} \\mathbf f = \\mathbf M\\,\\boldsymbol\\beta \\end{equation} where \\(\\mathbf M\\) is the design matrix which depends on some nonlinear parameters \\(\\boldsymbol\\theta\\) : \\[\\begin{equation} \\mathbf{M}\\equiv \\begin{pmatrix} \\tilde{A}(t_1;\\boldsymbol\\theta) & 1 \\\\ \\tilde{A}(t_2;\\boldsymbol\\theta) & 1 \\\\ \\vdots & \\vdots \\\\ \\tilde{A}(t_{N};\\boldsymbol\\theta) & 1 \\end{pmatrix} \\end{equation}\\] Assuming that we place a Gaussian prior on the linear parameters \\(\\boldsymbol\\beta\\) with mean \\(\\boldsymbol\\mu\\) and covariance \\(\\boldsymbol\\Lambda\\) , one can show that the marginal likelihood \\(\\ln\\int p(\\mathbf f|\\boldsymbol\\theta)\\,p(\\boldsymbol\\beta|\\boldsymbol\\theta)d\\boldsymbol\\beta\\) is given by \\[\\begin{equation} \\mathrm{LL}(\\boldsymbol\\theta)=-\\frac{1}{2}\\left( \\mathbf{f}-\\mathbf{M}\\boldsymbol{\\mu}\\right)^\\intercal\\left(\\mathbf{C} + \\mathbf{M}\\boldsymbol{\\Lambda}\\mathbf{M}^\\intercal\\right)^{-1} \\left( \\mathbf{f}-\\mathbf{M}\\boldsymbol{\\mu}\\right) - \\frac{1}{2}\\ln\\left| \\mathbf{C} + \\mathbf{M}\\boldsymbol{\\Lambda}\\mathbf{M}^\\intercal\\right| \\end{equation}\\] To compute the inverse and the determinant of the covariance matrix of marginalized likelihood we can use the matrix inversion lemma (see Appendix A3 of R&W ): \\[\\begin{align} & \\left(\\mathbf{C}+\\mathbf{M} \\boldsymbol{\\Lambda} \\mathbf{M}^{\\intercal}\\right)^{-1}=\\mathbf{C}^{-1}-\\mathbf{C}^{-1} \\mathbf{M}\\left(\\boldsymbol{\\Lambda}^{-1}+\\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\mathbf{M}\\right)^{-1} \\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\\\ & \\ln\\left|\\mathbf{C}+\\mathbf{M} \\mathbf{\\Lambda} \\mathbf{M}^{\\intercal}\\right|=\\ln|\\mathbf{C}| +\\ln|\\boldsymbol{\\Lambda}| + \\ln\\left|\\boldsymbol{\\Lambda}^{-1}+\\mathbf{M}^{\\intercal} \\mathbf{C}^{-1} \\mathbf{M}\\right| \\end{align}\\] However, if we marginalize over the linear parameters, how can we obtain their values in order to, for example, produce a plot of the model fit? The answer, from the paper linked above, is that the distribution over \\(\\boldsymbol\\beta\\) conditional on particular values of the nonlinear parameters \\(\\boldsymbol\\theta\\) is a Gaussian \\(\\mathcal{N}(\\boldsymbol\\beta;\\mathbf a,\\mathbf A)\\) where \\[\\begin{align} &\\mathbf{A}^{-1}=\\boldsymbol\\Lambda^{-1}+\\mathbf{M}^{\\intercal}\\mathbf{C}^{-1}\\mathbf{M} \\\\ &\\mathbf a = \\mathbf A\\left(\\boldsymbol\\Lambda^{-1}\\boldsymbol\\mu+\\mathbf{M}^{\\intercal}\\mathbf{C}^{-1}\\mathbf{f}\\right) \\end{align}\\] If we had posterior samples of the nonlinear parameters \\(\\boldsymbol\\theta\\) we could could use this distribution to generate samples of the linear parameters. In marginalized_log_likelihood I use the standard least squares solution for \\(\\boldsymbol\\beta\\) if the data covariance matrix is diagonal because it's faster than the matrix operations in \\(\\mathrm{LL}(boldsymbol\\theta)\\) . Otherwise I use the full analytic marginalization.","title":"Linear algebra"},{"location":"api/linalg/#caustics.linalg","text":"","title":"linalg"},{"location":"api/linalg/#caustics.linalg.marginalized_log_likelihood","text":"Compute the log-likelihood for a microlensing light curve marginalized over over the linear flux parameters \\(\\boldsymbol\\beta\\equiv(F_s, F_b)^\\intercal\\) . The function takes a list of magnification vectors, a list of observed fluxes and a list of inverse data covariance matrices as an input, one element of the list represents and independent set of observations, for instance light curves from different observatories. The total log-likelihood is then a sum of the log-likelihoods for each light curve. If dense_covariance is False, the inverse data covariance matrices are assumed to be 1D vectors containing the elements on the diagonal. In that case, the most efficient way to marginalize over the linear parameters in the likelihood is to solve the linear least squares problem conditional on fixed values of the nonlinear parameters (which determine the magnification). If dense_covariance is True, the inverse covariance matrices are assumed to be dense matrices. In that case we have to compute the full marginal likelihood. This increases the computational cost of the likelihood evaluation. Parameters: Name Type Description Default A_list list [ array_like ] List of 1D magnification arrays, one per independent observation. required fobs_list list [ array_like ] List of 1D observed flux arrays. required C_inv_list list [ array_like ] List of nverse data covariance matrices. If dense_covariance is False, this is a 1D vector containing the diagonal elements of the covariance matrix. If dense_covariance is True, this is a dense matrix. required dense_covariance bool Flag indicating whether C_inv is dense or diagonal. Defaults to False. False Lam_sd float Standard deviation of the Gaussian prior on the linear flux parameters. The prior is assumed to be a zero mean independent Gaussian with standard deviation Lam_sd for both linear parameters. Defaults to 1e04. 10000.0 Returns: Name Type Description tuple If dense_covariance is False, returns a tuple \\((\\boldsymbol\\beta, \\mathrm{LL}(\\boldsymbol\\theta))\\) containing the least-squares solution for the linear parameters and the log-likelihood. Otherwise, the first element of the tuple is 0.","title":"marginalized_log_likelihood()"},{"location":"api/point_source/","text":"Point source \u00a4 caustics.point_source \u00a4 mag_point_source ( w , nlenses = 2 , roots_itmax = 2500 , roots_compensated = False , ** params ) \u00a4 Compute the magnification of a point source for a system with nlenses lenses. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i\\psi}\\) . For a single lens lens the magnification is computed analytically. For binary and triple lenses computing the magnification involves solving for the roots of a complex polynomial with degree ( nlenses **2 + 1) using the Elrich-Aberth algorithm. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Parameters: Name Type Description Default w array_like Source position in the complex plane. required nlenses int Number of lenses in the system. 2 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description array_like The point source magnification evaluated at w. critical_and_caustic_curves ( npts = 200 , nlenses = 2 , ** params ) \u00a4 Compute critical and caustic curves for visualization purposes. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Parameters: Name Type Description Default npts int Number of points to when computing the critical curves. 200 nlenses int Number of lenses in the system. 2 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required Returns: Name Type Description tuple Tuple (critical_curves, caustic_curves) where both elements are arrays with shape ( nlenses , npts ) containing continuous segments of the critical curves and caustics.","title":"Point source"},{"location":"api/point_source/#point-source","text":"","title":"Point source"},{"location":"api/point_source/#caustics.point_source","text":"","title":"point_source"},{"location":"api/point_source/#caustics.point_source.mag_point_source","text":"Compute the magnification of a point source for a system with nlenses lenses. If nlenses is 2 (binary lens) or 3 (triple lens), the coordinate system is set up such that the the origin is at the center of mass of the first two lenses which are both located on the real line. The location of the first lens is \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) . The optional third lens is located at an arbitrary position in the complex plane \\(r_3e^{-i\\psi}\\) . For a single lens lens the magnification is computed analytically. For binary and triple lenses computing the magnification involves solving for the roots of a complex polynomial with degree ( nlenses **2 + 1) using the Elrich-Aberth algorithm. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Parameters: Name Type Description Default w array_like Source position in the complex plane. required nlenses int Number of lenses in the system. 2 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required roots_itmax int Number of iterations for the root solver. 2500 roots_compensated bool Whether to use the compensated arithmetic version of the Ehrlich-Aberth root solver. False Returns: Name Type Description array_like The point source magnification evaluated at w.","title":"mag_point_source()"},{"location":"api/point_source/#caustics.point_source.critical_and_caustic_curves","text":"Compute critical and caustic curves for visualization purposes. If nlenses is 2 only the parameters s and q should be specified. If nlenses is 3, the parameters s , q , q3 , r3 and psi should be specified. Parameters: Name Type Description Default npts int Number of points to when computing the critical curves. 200 nlenses int Number of lenses in the system. 2 s float Separation between the two lenses. The first lens is located at \\(-sq/(1 + q)\\) and the second lens is at \\(s/(1 + q)\\) on the real line. required q float Mass ratio defined as \\(m_2/m_1\\) . required q3 float Mass ratio defined as \\(m_3/m_1\\) . required r3 float Magnitude of the complex position of the third lens. required psi float Phase angle of the complex position of the third lens. required Returns: Name Type Description tuple Tuple (critical_curves, caustic_curves) where both elements are arrays with shape ( nlenses , npts ) containing continuous segments of the critical curves and caustics.","title":"critical_and_caustic_curves()"}]}